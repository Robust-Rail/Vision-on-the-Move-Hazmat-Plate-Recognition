{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077147bb-cf19-4906-ab20-ebac69b81a81",
   "metadata": {},
   "source": [
    "# UN number detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6c1be-70c4-4717-b2eb-fcc06698b492",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "For this project, we have been tasked with developing a machine learning model capable of recognizing UN number hazard plates. These plates, commonly displayed on freight train wagons, indicate the types of hazardous materials being transported. The successful implementation of this model will contribute to a more efficient and secure railway system across the EU.\n",
    "\n",
    "<img src=\"images/hazard_plate.jpg\" alt=\"Hazard Plate\" width=\"500\"/>\n",
    "\n",
    "The hazard plates play a crucial role in ensuring the safety of transportation by providing essential information about the nature of the substances on board, such as flammability, toxicity, or corrosiveness. By automating the recognition process with machine learning, the handling and tracking of these hazardous materials can be streamlined, reducing manual labor and minimizing potential human errors.\n",
    " Determine business objectives\n",
    "\n",
    "### Determine business objectives\n",
    "#### Background\n",
    "The specific expectations and objectives of the EU for this project are not yet fully defined, but the initiative's roots are clear. This project is spearheaded by the University of Twente, with researcher Mellisa Tijink serving as our supervisor. Our team, composed of pre-master's Computer Science students, has been tasked with developing the machine learning model. Mellisa Tijink plays a pivotal role as the intermediary between our team and major stakeholders, including ProRail, the EU, and other experts in the field.\n",
    "\n",
    "This project is part of a broader initiative aimed at enhancing rail freight operations within Europe, aligning with the EU’s goals for improved efficiency and safety. More information on the initiative can be found on the official project site: [EU Rail FP5](https://projects.rail-research.europa.eu/eurail-fp5/).\n",
    "\n",
    "Flagship Project 5: *TRANS4M-R aims to establish rail freight as the backbone of a low-emission, resilient European logistics chain that meets end-user needs. It focuses on two main technological clusters: 'Full Digital Freight Train Operation' and 'Seamless Freight Operation', which will develop and demonstrate solutions to increase rail capacity, efficiency, and cross-border coordination. By integrating Digital Automatic Coupler (DAC) solutions with software-defined systems, the project seeks to optimize network management and enhance cooperation among infrastructure managers. The ultimate goal is to create an EU-wide, interoperable rail freight framework with unified technologies and seamless operations across borders and various stakeholders, boosting the EU transport and logistics sector.*\n",
    "\n",
    "#### Business objectives\n",
    "\n",
    "**Primary Objective:** Develop an object detection model for UN number hazard plates on freight wagons.\n",
    "\n",
    "**Sub-objectives:**\n",
    "1. Detect and identify UN number hazard plates: Ensure the model can accurately locate hazard plates on freight wagons. \n",
    "2. Read and interpret the UN numbers: Implement recognition capabilities to accurately read the numbers on the detected plates.\n",
    "3. Ensure model robustness and accuracy: Train the model to achieve high accuracy and reliability under various conditions (e.g., different lighting, weather).\n",
    "4. Optimize model for speed: Make sure the model runs efficiently and in real-time to function on moving trains.\n",
    "5. Adapt the model for moving environments: Design and test the model to handle the unique challenges of detecting and reading plates on trains in motion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4411a987",
   "metadata": {},
   "source": [
    "### Assess Situation\n",
    "\n",
    "#### Inventory of resources\n",
    "\n",
    "**Business Experts:** Our team currently lacks extensive expertise in this area. We can consult Melissa for some questions, and we have an upcoming interview with a Swedish expert in the field of UN number hazard plates.\n",
    "\n",
    "**Data Mining Team:** \n",
    "- Melissa Tijink (Researcher in Data Management & Biometrics/Electrical Engineering, Mathematics, and Computer Science)\n",
    "- Ewaldo Nieuwenhuis (Pre-master student in Computer Science)\n",
    "- Stanislav Levendeev (Pre-master student in Computer Science)\n",
    "\n",
    "**Data:**\n",
    "1. **Video Data of Freight Trains:** This consists of video footage of moving freight trains, where the freight wagons should display the UN numbers.\n",
    "2. **Line Scan Camera Pictures:** These are high-resolution images of the train, but they are very spread out. It is still uncertain if these will be useful.\n",
    "3. **Photos of ADR Warning Signs:** These are images of ADR signs on freight trains. However, this is not exactly what we need since our objective is to build a model that recognizes UN numbers.\n",
    "\n",
    "**Computing Resources:** We have access to a cluster from the University of Twente, which we can use to train or fine-tune our model.\n",
    "\n",
    "**Software:** We will use Python, Jupyter Notebook, Keras, PyTorch, and TensorFlow for analyzing, cleaning, preparing the data, and modeling. For data labeling, we will use [CVAT](https://www.cvat.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f6a3d9",
   "metadata": {},
   "source": [
    "### Requirements, assumptions, and constraints\n",
    "\n",
    "##### Requirements\n",
    "- Object detection capability for UN number hazard plates.\n",
    "- Text recognition to read and extract UN numbers.\n",
    "- High accuracy and precision in detection and recognition.\n",
    "- Robust performance under varying conditions (weather, lighting, speed).\n",
    "- Speed optimization for fast processing with minimal lag\n",
    "- Real-time processing for operation on moving trains.\n",
    "\n",
    "##### Assumptions\n",
    "- Consistent access to a high-performance computational cluster for model training and testing.\n",
    "- The high-performance cluster is necessary due to the heavy processing demands of deep learning models.\n",
    "- Local machines are not sufficient for the required high computational tasks.\n",
    "- Project-specific data, including images and videos of freight trains with hazard plates, will be provided as planned.\n",
    "- Data will include varied conditions (different lighting and weather) to ensure robustness.\n",
    "- Access to diverse data is essential for creating a model that generalizes well to real-world scenarios.\n",
    "- If the planned data is unavailable, additional time will be needed to source and prepare alternative public datasets.\n",
    "- Sourcing alternative datasets may affect the project timeline and the quality of the final outcomes.\n",
    "- The stakeholders will provide timely feedback to guide any changes or adaptations needed in the project.\n",
    "\n",
    "##### Constraints\n",
    "- The team has restricted experience with advanced object detection methods, which may impact the initial development and refinement of the model.\n",
    "- Most of the available data is not labeled, presenting a challenge for training supervised machine learning models. Some labeled data exists but belongs to another researcher, and access to it is uncertain.\n",
    "- The project must be completed within a short, 9-week period, which constrains the depth and breadth of potential research and model development.\n",
    "- The dataset may be skewed with an overrepresentation of specific UN numbers from certain wagons, which could limit the model's ability to generalize across different scenarios.\n",
    "- The size of the dataset makes it difficult to filter out specific wagons or relevant segments efficiently, posing a challenge for data processing and targeted training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac8acb",
   "metadata": {},
   "source": [
    "#### Risks and Contingencies\n",
    "\n",
    "**1. Lack of Data Access:**  \n",
    "*Risk:* Currently, we do not have access to the necessary video or linescan data, and there is a risk that we may never obtain it.  \n",
    "*Contingency Action:* Search for publicly available open-source datasets containing UN codes to proceed with model training and development.\n",
    "\n",
    "**2. Loss of Access to the Computational Cluster:**  \n",
    "*Risk:* While we currently have access to a high-performance cluster for training, loading, and fine-tuning models, there is a chance of losing this access due to technical failures or maintenance issues.  \n",
    "*Contingency Action:* Prepare to train, load, and fine-tune a smaller version of the model locally on personal computers.\n",
    "\n",
    "**3. Unavailability of Labeling Software:**  \n",
    "*Risk:* We plan to label the data with the help of our supervisor, Melissa, which is essential for fine-tuning and evaluating the model. If this step is delayed or cannot occur, it will impede progress.  \n",
    "*Contingency Action:* Learn how to use CVAT (Computer Vision Annotation Tool) and set it up on personal laptops to carry out data labeling independently.\n",
    "\n",
    "**4. Inaccessibility of Personal Laptops:**  \n",
    "*Risk:* Access to our laptops is crucial for development, data handling, and connecting to the cluster. If our laptops become unusable due to malfunction, our work will be disrupted.  \n",
    "*Contingency Action:* Use backup laptops that are ready for project work to ensure continuity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9600fa72",
   "metadata": {},
   "source": [
    "#### Terminology\n",
    "\n",
    "**Business Terminology:**\n",
    "- **UN Number Hazard Plates**: Identification plates with UN numbers that indicate the nature of hazardous materials, improving safety during transport.\n",
    "- **Freight Trains**: Trains used for transporting goods, especially relevant when carrying hazardous materials.\n",
    "- **Flagship Project 5**: A project within the European \"Europe’s Rail\" initiative, focused on applying technologies to enhance rail transport safety.\n",
    "- **ADR (European Agreement concerning the International Carriage of Dangerous Goods by Road)**: International regulations governing the transport of hazardous goods.\n",
    "- **ProRail**: The Dutch railway network manager responsible for maintaining the railways.\n",
    "- **Line-Scan Camera**: A camera that captures images one line at a time for capturing objects like fast-moving trains.\n",
    "\n",
    "**Data Mining Terminology:**\n",
    "- **CRISP-DM (Cross-Industry Standard Process for Data Mining)**: A widely used methodology for managing data mining projects, consisting of six phases:\n",
    "  - **Business Understanding**: Defining objectives from a business perspective.\n",
    "  - **Data Understanding**: Collecting and analyzing data to gain insights.\n",
    "  - **Data Preparation**: Preparing data, such as annotating and normalizing, for model training.\n",
    "  - **Modeling**: Selecting and training models for the desired task.\n",
    "  - **Evaluation**: Assessing model performance using specific metrics.\n",
    "  - **Deployment**: Implementing the model in real-world applications.\n",
    "\n",
    "- **Object Detection**: Identifying specific objects (e.g., hazard plates) within images or videos.\n",
    "- **Optical Character Recognition (OCR)**: Extracting text from images, used here to read numbers on hazard plates.\n",
    "- **YOLO (You Only Look Once)**: A fast object detection model ideal for real-time applications.\n",
    "- **Faster R-CNN**: A more accurate but slightly slower object detection model, suitable for complex environments.\n",
    "- **Annotation**: Marking data (e.g., video frames) with labels like bounding boxes to create ground truth for model training.\n",
    "- **Bounding Boxes**: Rectangular boxes used in image processing to define regions of interest around an object.\n",
    "- **Normalization**: Adjusting data to a standard scale to ensure consistency in model input.\n",
    "- **Augmentation**: Enhancing training data through techniques like contrast adjustment to improve model robustness.\n",
    "- **Average Precision (AP)**: A metric for evaluating the accuracy of object detection models.\n",
    "- **Tesseract**: A commonly used OCR tool for extracting alphanumeric text from images.\n",
    "- **HOG (Histogram of Oriented Gradients)**: A feature descriptor used in object detection, especially for detecting shapes or text.\n",
    "- **Saliency Detection**: An algorithmic technique to identify key areas within images for focused analysis.\n",
    "- **Support Vector Regression (SVR)**: A machine learning algorithm for regression tasks, sometimes used to create likelihood maps for image processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68f479",
   "metadata": {},
   "source": [
    "### Determine Data Mining Goals\n",
    "\n",
    "#### Data Mining Goals\n",
    "**Primary Data Mining Goal:** Create and train an object detection model capable of identifying and interpreting UN number hazard plates on freight wagons in real-time.\n",
    "\n",
    "**Specific Data Mining Goals:**\n",
    "1. **Object Detection and Localization**: Develop a model that achieves a high AP score for accurately detecting and localizing hazard plates on freight wagons within each video frame.\n",
    "\n",
    "2. **OCR for UN Number Extraction:** Use Tesseract to apply Optical Character Recognition (OCR) for accurately reading UN numbers on detected plates, aiming to optimize precision and minimize errors in text recognition.\n",
    "\n",
    "3. **Robustness Across Variable Conditions**: Enhance the model’s robustness by training it on datasets representing diverse lighting and weather conditions, with a goal to maintain high AP scores across these environments.\n",
    "\n",
    "4. **Optimization for Real-Time Processing**: Implement real-time object detection and OCR capabilities to ensure the model operates at a frame rate suitable for analyzing images from moving trains.\n",
    "\n",
    "#### Data Mining Success Criteria\n",
    "\n",
    "- **Object Detection AP**: Achieve an Mean Average Precision (mAP) of at least 0.70 for detecting and localizing hazard plates across varied conditions.\n",
    "- **OCR Precision for UN Numbers**: Ensure the Tesseract OCR module achieves high accuracy in reading UN numbers, even under challenging conditions, with a target precision score above 0.95.\n",
    "- **Processing Speed**: Ensure the model achieves a processing time per frame under 100 milliseconds to maintain real-time functionality.\n",
    "- **Environmental Robustness**: Maintain consistent mAP scores across different lighting and weather conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c78e4-b34a-42c5-b82e-194acd0f7fed",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "### Collect Initial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fbf39b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/stani/Documents/WagonVideos\n",
      "./data/output_frames\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Directory containing video files\n",
    "video_directory = os.environ[\"PATH_TO_DATA\"]\n",
    "print (video_directory)\n",
    "\n",
    "# Specify output directory for detected frames\n",
    "output_path = os.environ[\"OUTPUT_PATH\"]\n",
    "output_directory = None\n",
    "if not os.path.exists(output_path):\n",
    "    output_directory = './data/output_frames'\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "else:\n",
    "    output_directory = output_path\n",
    "print (output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a5a672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>filename</th>\n",
       "      <th>fps</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>resolution</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>file_size_mb</th>\n",
       "      <th>hash</th>\n",
       "      <th>train_detected</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1692840930.mp4</td>\n",
       "      <td>12.421977</td>\n",
       "      <td>4970</td>\n",
       "      <td>3840</td>\n",
       "      <td>2160</td>\n",
       "      <td>3840x2160</td>\n",
       "      <td>400.097333</td>\n",
       "      <td>220.700567</td>\n",
       "      <td>cbb62c456e3a52f8bc36d82a0e634e23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1693191052.mp4</td>\n",
       "      <td>12.335847</td>\n",
       "      <td>4936</td>\n",
       "      <td>3840</td>\n",
       "      <td>2160</td>\n",
       "      <td>3840x2160</td>\n",
       "      <td>400.134667</td>\n",
       "      <td>190.600795</td>\n",
       "      <td>c2c35a3f2fd6e73fee4af101aa283508</td>\n",
       "      <td>True</td>\n",
       "      <td>16.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1692872809.mp4</td>\n",
       "      <td>12.261546</td>\n",
       "      <td>4906</td>\n",
       "      <td>3840</td>\n",
       "      <td>2160</td>\n",
       "      <td>3840x2160</td>\n",
       "      <td>400.112667</td>\n",
       "      <td>282.826048</td>\n",
       "      <td>0d43b00affad06a510700d1d05b00f5d</td>\n",
       "      <td>True</td>\n",
       "      <td>85.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1693192374.mp4</td>\n",
       "      <td>12.362800</td>\n",
       "      <td>4181</td>\n",
       "      <td>3840</td>\n",
       "      <td>2160</td>\n",
       "      <td>3840x2160</td>\n",
       "      <td>338.192000</td>\n",
       "      <td>174.538270</td>\n",
       "      <td>8bfeb49ba5f82ee5d639ae611be0d456</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1692832634.mp4</td>\n",
       "      <td>12.381327</td>\n",
       "      <td>4954</td>\n",
       "      <td>3840</td>\n",
       "      <td>2160</td>\n",
       "      <td>3840x2160</td>\n",
       "      <td>400.118667</td>\n",
       "      <td>219.614924</td>\n",
       "      <td>c9b651c8d8c07dea0222cc281f1a54f0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        filename        fps  frame_count  width  height  \\\n",
       "0           0  1692840930.mp4  12.421977         4970   3840    2160   \n",
       "1           1  1693191052.mp4  12.335847         4936   3840    2160   \n",
       "2           2  1692872809.mp4  12.261546         4906   3840    2160   \n",
       "3           3  1693192374.mp4  12.362800         4181   3840    2160   \n",
       "4           4  1692832634.mp4  12.381327         4954   3840    2160   \n",
       "\n",
       "  resolution  duration_seconds  file_size_mb  \\\n",
       "0  3840x2160        400.097333    220.700567   \n",
       "1  3840x2160        400.134667    190.600795   \n",
       "2  3840x2160        400.112667    282.826048   \n",
       "3  3840x2160        338.192000    174.538270   \n",
       "4  3840x2160        400.118667    219.614924   \n",
       "\n",
       "                               hash  train_detected  confidence  \n",
       "0  cbb62c456e3a52f8bc36d82a0e634e23           False         NaN  \n",
       "1  c2c35a3f2fd6e73fee4af101aa283508            True       16.66  \n",
       "2  0d43b00affad06a510700d1d05b00f5d            True       85.18  \n",
       "3  8bfeb49ba5f82ee5d639ae611be0d456           False         NaN  \n",
       "4  c9b651c8d8c07dea0222cc281f1a54f0           False         NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all filenames in the directory\n",
    "video_files = [f for f in os.listdir(video_directory) if f.endswith(('.mp4'))]\n",
    "video_files[0]\n",
    "df = pd.read_csv('data/data_understanding_2024-11-28.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef235ad",
   "metadata": {},
   "source": [
    "### Describe Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416fcb9",
   "metadata": {},
   "source": [
    "**Column Description:**\n",
    "\n",
    "- **Unnamed: 0**: The ID of the video.\n",
    "- **filename**: The name of the file, including the `.mp4` extension.\n",
    "- **fps**: Frames per second.\n",
    "- **frame_count**: The total number of frames in the video.\n",
    "- **width**: The width of the video in pixels.\n",
    "- **height**: The height of the video in pixels.\n",
    "- **resolution**: The video resolution, expressed as `width x height`.\n",
    "- **duration_seconds**: The video's duration in seconds.\n",
    "- **hash**: Hash of the video to check if it is original\n",
    "- **file_size_mb**: The file size in megabytes.\n",
    "- **train_detected**: Indicates whether a train was detected using a YOLO model. If the model's confidence score exceeded 10%, a train is considered detected, though this may not always be accurate.\n",
    "- **confidence**: The confidence score indicating how likely it is that the video contains a train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e697cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd71399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fps</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>file_size_mb</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>238.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>209.378313</td>\n",
       "      <td>15.899970</td>\n",
       "      <td>2859.146988</td>\n",
       "      <td>3731.739759</td>\n",
       "      <td>2099.103614</td>\n",
       "      <td>204.005407</td>\n",
       "      <td>155.239357</td>\n",
       "      <td>45.742101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>122.441918</td>\n",
       "      <td>8.547737</td>\n",
       "      <td>1956.206607</td>\n",
       "      <td>345.947372</td>\n",
       "      <td>194.595397</td>\n",
       "      <td>146.467175</td>\n",
       "      <td>113.477949</td>\n",
       "      <td>28.815157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.352059</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>2.092000</td>\n",
       "      <td>3.296003</td>\n",
       "      <td>10.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>103.500000</td>\n",
       "      <td>12.319158</td>\n",
       "      <td>852.500000</td>\n",
       "      <td>3840.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>59.624667</td>\n",
       "      <td>47.954046</td>\n",
       "      <td>16.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>207.000000</td>\n",
       "      <td>12.403184</td>\n",
       "      <td>2984.000000</td>\n",
       "      <td>3840.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>239.947333</td>\n",
       "      <td>156.125751</td>\n",
       "      <td>44.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>315.500000</td>\n",
       "      <td>15.070671</td>\n",
       "      <td>4889.500000</td>\n",
       "      <td>3840.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>362.675167</td>\n",
       "      <td>227.414033</td>\n",
       "      <td>72.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>422.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9080.000000</td>\n",
       "      <td>3840.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>800.157333</td>\n",
       "      <td>530.429472</td>\n",
       "      <td>94.860000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         fps  frame_count        width       height  \\\n",
       "count  415.000000  415.000000   415.000000   415.000000   415.000000   \n",
       "mean   209.378313   15.899970  2859.146988  3731.739759  2099.103614   \n",
       "std    122.441918    8.547737  1956.206607   345.947372   194.595397   \n",
       "min      0.000000    7.352059    46.000000  1920.000000  1080.000000   \n",
       "25%    103.500000   12.319158   852.500000  3840.000000  2160.000000   \n",
       "50%    207.000000   12.403184  2984.000000  3840.000000  2160.000000   \n",
       "75%    315.500000   15.070671  4889.500000  3840.000000  2160.000000   \n",
       "max    422.000000   60.000000  9080.000000  3840.000000  2160.000000   \n",
       "\n",
       "       duration_seconds  file_size_mb  confidence  \n",
       "count        415.000000    415.000000  238.000000  \n",
       "mean         204.005407    155.239357   45.742101  \n",
       "std          146.467175    113.477949   28.815157  \n",
       "min            2.092000      3.296003   10.060000  \n",
       "25%           59.624667     47.954046   16.280000  \n",
       "50%          239.947333    156.125751   44.140000  \n",
       "75%          362.675167    227.414033   72.790000  \n",
       "max          800.157333    530.429472   94.860000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b224437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 415 entries, 0 to 414\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        415 non-null    int64  \n",
      " 1   filename          415 non-null    object \n",
      " 2   fps               415 non-null    float64\n",
      " 3   frame_count       415 non-null    int64  \n",
      " 4   width             415 non-null    int64  \n",
      " 5   height            415 non-null    int64  \n",
      " 6   resolution        415 non-null    object \n",
      " 7   duration_seconds  415 non-null    float64\n",
      " 8   file_size_mb      415 non-null    float64\n",
      " 9   hash              415 non-null    object \n",
      " 10  train_detected    415 non-null    bool   \n",
      " 11  confidence        238 non-null    float64\n",
      "dtypes: bool(1), float64(4), int64(4), object(3)\n",
      "memory usage: 36.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ae726c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "filename              0\n",
       "fps                   0\n",
       "frame_count           0\n",
       "width                 0\n",
       "height                0\n",
       "resolution            0\n",
       "duration_seconds      0\n",
       "file_size_mb          0\n",
       "hash                  0\n",
       "train_detected        0\n",
       "confidence          177\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a691589",
   "metadata": {},
   "source": [
    "### Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b83c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 177 videos there haven't been detected any trains. Of a total of 415 videos.\n"
     ]
    }
   ],
   "source": [
    "no_trains = sum(df['train_detected'] == 0)\n",
    "print(f\"On {no_trains} videos there haven't been detected any trains. Of a total of {df.shape[0]} videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b484839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 42.7% of all videos.\n"
     ]
    }
   ],
   "source": [
    "no_trains_percentage = no_trains / df.shape[0] * 100\n",
    "print(f\"This is {no_trains_percentage:.1f}% of all videos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a8012ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hash\n",
       "45e762aff569946e57713e054caa1880    1\n",
       "cbb62c456e3a52f8bc36d82a0e634e23    1\n",
       "c2c35a3f2fd6e73fee4af101aa283508    1\n",
       "0d43b00affad06a510700d1d05b00f5d    1\n",
       "8bfeb49ba5f82ee5d639ae611be0d456    1\n",
       "                                   ..\n",
       "85fcf8268db3d7320c2749693238b542    1\n",
       "d66b165ab6f17c812e0cdfbd85b1c691    1\n",
       "fd943adef5f34141322e5386b0bc6bb4    1\n",
       "626cdbbbb56b23d06bbeebdb0a407aa2    1\n",
       "dccd00fcf6cd02deca8392dbc759e83c    1\n",
       "Name: count, Length: 415, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hash'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2f9d2",
   "metadata": {},
   "source": [
    "They seem to be all orginal in terms of hashing, we probably cannot determine duplicates by hash alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbd1f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MP4 video\n",
    "video = \"1690279852.mp4\"\n",
    "video2 = \"1690281303.mp4\"\n",
    "video_path = video_directory+'/'+video\n",
    "video2_path = video_directory+'/'+video2\n",
    "# Embed video in the notebook\n",
    "\n",
    "def get_video_html(video_path):\n",
    "    return HTML(f\"\"\"\n",
    "      <h1>Video {video_path}</h1>\n",
    "      <video width=\"480\" height=\"320\" controls>\n",
    "        <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "        Your browser does not support the video tag.\n",
    "      </video>\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f97f8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <h1>Video C:/Users/stani/Documents/WagonVideos/1690279852.mp4</h1>\n",
       "      <video width=\"480\" height=\"320\" controls>\n",
       "        <source src=\"C:/Users/stani/Documents/WagonVideos/1690279852.mp4\" type=\"video/mp4\">\n",
       "        Your browser does not support the video tag.\n",
       "      </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_video_html(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f81bec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <h1>Video C:/Users/stani/Documents/WagonVideos/1690281303.mp4</h1>\n",
       "      <video width=\"480\" height=\"320\" controls>\n",
       "        <source src=\"C:/Users/stani/Documents/WagonVideos/1690281303.mp4\" type=\"video/mp4\">\n",
       "        Your browser does not support the video tag.\n",
       "      </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_video_html(video2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acbbfd3",
   "metadata": {},
   "source": [
    "**These are the same videos, the second video is only one second longer than the first video. There are duplicate video's in this dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "452e79ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_detected\n",
       "True     238\n",
       "False    177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train_detected'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3fb58bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    238.000000\n",
       "mean      45.742101\n",
       "std       28.815157\n",
       "min       10.060000\n",
       "25%       16.280000\n",
       "50%       44.140000\n",
       "75%       72.790000\n",
       "max       94.860000\n",
       "Name: confidence, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['confidence'].isnull() == False]['confidence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb32a5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Minimal confidence: 10.06, maximal confidence: 94.86, average confidence: 45.74</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(f\"<b>Minimal confidence: {df['confidence'].min():.2f}, maximal confidence: {df['confidence'].max():.2f}, average confidence: {df['confidence'].mean():.2f}</b>\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29ad80ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video with maximal confidence: 1696612976.mp4 (94.86%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <h1>Video C:/Users/stani/Documents/WagonVideos/1696612976.mp4</h1>\n",
       "      <video width=\"480\" height=\"320\" controls>\n",
       "        <source src=\"C:/Users/stani/Documents/WagonVideos/1696612976.mp4\" type=\"video/mp4\">\n",
       "        Your browser does not support the video tag.\n",
       "      </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_max_confidence = df[df['confidence'] == df['confidence'].max()].iloc[0]['filename']\n",
    "video_min_confidence = df[df['confidence'] == df['confidence'].min()].iloc[0]['filename']\n",
    "\n",
    "print(f\"Video with maximal confidence: {video_max_confidence} ({df[\"confidence\"].max():.2f}%)\")\n",
    "get_video_html(video_directory+\"/\"+video_max_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "909e1a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video with minimal confidence: 1692994965.mp4 (10.06%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <h1>Video C:/Users/stani/Documents/WagonVideos/1692994965.mp4</h1>\n",
       "      <video width=\"480\" height=\"320\" controls>\n",
       "        <source src=\"C:/Users/stani/Documents/WagonVideos/1692994965.mp4\" type=\"video/mp4\">\n",
       "        Your browser does not support the video tag.\n",
       "      </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Video with minimal confidence: {video_min_confidence} ({df[\"confidence\"].min():.2f}%)\")\n",
    "get_video_html(video_directory+\"/\"+video_min_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2912fa3",
   "metadata": {},
   "source": [
    "**In the second video, trains are detected, but there are no actual trains present. This indicates that the 'train_detected' column lacks certainty. It may be more effective for a human to review and filter videos to identify those with trains and those without. Alternatively, training a model specifically to recognize freight trains could be considered, although this falls outside the scope of this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c7ce69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "010e6cfa",
   "metadata": {},
   "source": [
    "The frames per second (FPS) in your video data can influence the performance of training your model. FPS affects the temporal resolution and the amount of data fed into the model. When training on video data, the FPS determines how many frames are available to capture motion or other temporal patterns, which can influence model performance.\n",
    "\n",
    "For example, if you use a higher FPS, your model will have more frames to analyze within a given time frame, potentially improving its ability to capture finer details in motion (e.g., in object detection or action recognition tasks). However, processing more frames per second can also lead to higher computational costs and may require more memory and processing power, which might reduce training efficiency unless properly optimized.\n",
    "[source 1](https://library.fiveable.me/key-terms/deep-learning-systems/frames-per-second-fps)\n",
    "\n",
    "\n",
    "Conversely, lower FPS can reduce computational demands but may also decrease the temporal resolution of your data, making it harder for your model to accurately capture fast movements or dynamic changes. Depending on your specific use case, you'll need to balance FPS with your model's ability to process the data effectively while managing computational resources.\n",
    "[source 2](https://paulbridger.com/posts/video-analytics-pipeline-tuning/)\n",
    "\n",
    "It's also important to consider other factors like video resolution and preprocessing techniques, which could further affect how FPS influences your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72db335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acc5c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df, column, xlabel, ylabel=\"Frequency\", bins=10):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(df[column], bins=bins, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    plt.title(f\"Distribution of {xlabel}\", fontsize=14)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "699723f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_distribution(df, 'fps', xlabel='Frames Per Second (FPS)')\n",
    "plot_distribution(df, 'frame_count', xlabel='Total Frames', bins=20)\n",
    "plot_distribution(df, 'duration_seconds', xlabel='Duration (seconds)', bins=20)\n",
    "plot_distribution(df, 'file_size_mb', xlabel='File Size (MB)', bins=15)\n",
    "plot_distribution(df, 'resolution', xlabel='Resolution', bins=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8994d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def plot_resolutions(df):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(df['width'], df['height'], c='orange', alpha=0.7, edgecolors='black')\n",
    "    plt.title(\"Resolution Scatter Plot (Width vs Height)\", fontsize=14)\n",
    "    plt.xlabel(\"Width (pixels)\", fontsize=12)\n",
    "    plt.ylabel(\"Height (pixels)\", fontsize=12)\n",
    "    plt.grid(linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "plot_resolutions(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4ad84",
   "metadata": {},
   "source": [
    "### Verify Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe66bb62-a05b-48d6-8c54-ecc7d76de4d8",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6d330",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "866f1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7e7aa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "C:\\Users\\stani\\.cache\\kagglehub\\datasets\\stanislavlevendeev\\hazmat-detection\\versions\\11\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"stanislavlevendeev/hazmat-detection\")\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(path)\n",
    "print(device)\n",
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93bad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.51 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:\\Users\\stani\\.cache\\kagglehub\\datasets\\stanislavlevendeev\\hazmat-detection\\versions\\11\\yolo\\dataset.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train24, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train24\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\stani\\.cache\\kagglehub\\datasets\\stanislavlevendeev\\hazmat-detection\\versions\\11\\yolo\\labels\\train... 2896 images, 2537 backgrounds, 0 corrupt:  62%|██████▏   | 2811/4559 [00:14<00:01, 1049.97it/s]"
     ]
    }
   ],
   "source": [
    "# Train the model on the COCO8 example dataset for 100 epochs\n",
    "results = model.train(data=path+'\\\\yolo\\\\dataset.yaml', epochs=1)\n",
    "\n",
    "# Run inference with the YOLO11n model on the 'bus.jpg' image\n",
    "results = model(f\"{path}\\\\yolo\\\\images\\\\train\\\\1690281365_00001.jpg\")\n",
    "model.save(\"yolo11n_trained.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edc5e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def draw_rectangles(image_path, results):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    img_height, img_width, _ = image.shape\n",
    "    boxes = results.boxes   \n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max = map(int, box.xyxy[0])  # Convert to integers\n",
    "        confidence = box.conf[0]  # Confidence score\n",
    "        class_id = int(box.cls[0])  # Class ID\n",
    "        label = results.names[class_id]  # Class label\n",
    "\n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "        # Put the label and confidence score\n",
    "        cv2.putText(image, f\"{label} {confidence:.2f}\", (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    \n",
    "    # Convert BGR image to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the image using matplotlib\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a9042",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mstani\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mHIN\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUN-number-detection\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtest.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "results = model(f\"C:\\\\Users\\\\stani\\\\Documents\\\\Code\\\\Python\\\\HIN\\\\UN-number-detection\\\\images\\\\test.png\")\n",
    "print(\"Inference Results:\")\n",
    "\n",
    "for result in results:\n",
    "    print(result.boxes)\n",
    "    draw_rectangles(result.path, result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ad997b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f78f46",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011cf571",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
