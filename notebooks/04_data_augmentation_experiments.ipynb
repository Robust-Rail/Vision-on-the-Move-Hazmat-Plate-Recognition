{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61feee27",
   "metadata": {},
   "source": [
    "# Data augmentation Experiments\n",
    "\n",
    "For this project we will implement different types of data augmentations as well as custom data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee70dc3",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96453461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradScaler is used for mixed precision training in PyTorch.\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import tqdm\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3942d992",
   "metadata": {},
   "source": [
    "Classes and augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e078d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ewald\\Documents\\un-number-detection\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ewald\\Documents\\un-number-detection\\.venv\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# Import necessary functions and classes\n",
    "from un_detector.data.datasets import HazmatDataset \n",
    "from un_detector.data.augmentation import ( \n",
    "    get_augmented_transform,\n",
    "    visualize_augmentations,\n",
    "    generate_named_augmented_image, \n",
    "    visualize_weather_augmentations\n",
    ")\n",
    "from un_detector.utils.file_io import save_json, tensor_to_list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d770ccee",
   "metadata": {},
   "source": [
    "# Faster R-CNN Data Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37cdf08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GradScaler for mixed precision training\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3172f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your augmentations\n",
    "augmentations = get_augmented_transform(train=True)\n",
    "\n",
    "# Create directories to save augmented data\n",
    "base_dir = 'data/processed/prorail_coco_format/augmented_data'\n",
    "augmented_images_dir = base_dir + '/images'\n",
    "# Define the path for augmented annotations\n",
    "augmented_annotations_file = base_dir + '/annotations/instances_aug.json'\n",
    "os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "\n",
    "# Remove all files in the augmented_images_dir\n",
    "if os.path.exists(augmented_images_dir):\n",
    "    for file in os.listdir(augmented_images_dir):\n",
    "        file_path = os.path.join(augmented_images_dir, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove the file or symlink\n",
    "            elif os.path.isdir(file_path):\n",
    "                os.rmdir(file_path)  # Remove the directory (if empty)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting file {file_path}: {e}\")\n",
    "else:\n",
    "    print(f\"Directory {augmented_images_dir} does not exist.\")\n",
    "\n",
    "\n",
    "# Check if the augmented annotations file exists, if not create it\n",
    "if os.path.exists(augmented_annotations_file):\n",
    "    os.remove(augmented_annotations_file)  # Delete the existing file\n",
    "    print(f\"Deleted existing annotations file: {augmented_annotations_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a default structure for the augmented annotations\n",
    "categories_list = [\n",
    "    {\"id\": 1, \"name\": \"hazmat code\"}\n",
    "]\n",
    "\n",
    "# Load the original dataset, we use train in this instance to apply augmentations \n",
    "# but we will not use it for training and you might actually want to concat the train, validation and test datasets for this use case.\n",
    "original_dataset = HazmatDataset(\n",
    "    root='data/processed/prorail_coco_format/formatted_data/train',\n",
    "    ann_file='annotations/instances_train.json',\n",
    "    transforms=augmentations,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "augmented_annotations = {\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': categories_list\n",
    "}\n",
    "save_json(augmented_annotations, augmented_annotations_file)\n",
    "print(f\"Created new annotations file: {augmented_annotations_file}\")\n",
    "\n",
    "\n",
    "# Counter for image and annotation IDs\n",
    "img_id = len(augmented_annotations['images'])\n",
    "ann_id = len(augmented_annotations['annotations'])\n",
    "\n",
    "# Number of augmented images to create\n",
    "num_images_to_generate = 1000  # Set this to your desired limit\n",
    "\n",
    "# Iterate through the dataset with progress tracking\n",
    "generated_count = 0  # Counter for how many images we have generated\n",
    "for idx in tqdm(range(len(original_dataset)), desc=\"Augmenting dataset\"):\n",
    "    if generated_count >= num_images_to_generate:\n",
    "        break  # Stop when the desired number of augmented images is created\n",
    "    \n",
    "    img, target = original_dataset[idx]\n",
    "    \n",
    "    # Apply augmentations\n",
    "    aug_img, aug_target = augmentations(img, target)\n",
    "    # Save augmented image\n",
    "    aug_img_path = os.path.join(augmented_images_dir, f'aug_{img_id}.jpg')\n",
    "    if isinstance(aug_img, torch.Tensor):\n",
    "        aug_img = F.to_pil_image(aug_img)\n",
    "    aug_img.save(aug_img_path)\n",
    "    \n",
    "    # Update image annotation\n",
    "    augmented_annotations['images'].append({\n",
    "        'id': img_id,\n",
    "        'file_name': os.path.basename(aug_img_path),\n",
    "        'width': aug_img.width,\n",
    "        'height': aug_img.height\n",
    "    })\n",
    "    \n",
    "    # Update annotations\n",
    "    for box, label in zip(aug_target['boxes'], aug_target['labels']):\n",
    "        augmented_annotations['annotations'].append({\n",
    "            'id': ann_id,\n",
    "            'image_id': img_id,\n",
    "            'category_id': label.item(),\n",
    "            'bbox': [\n",
    "                box[0].item(), box[1].item(), \n",
    "                box[2].item() - box[0].item(), \n",
    "                box[3].item() - box[1].item()\n",
    "            ],\n",
    "            'area': (box[2] - box[0]) * (box[3] - box[1]),\n",
    "            'iscrowd': 0\n",
    "        })\n",
    "        ann_id += 1\n",
    "\n",
    "    # Update the image and annotation IDs\n",
    "    img_id += 1\n",
    "    generated_count += 1  # Increase the generated image counter\n",
    "\n",
    "# Convert tensors to lists before saving the annotations\n",
    "augmented_annotations = tensor_to_list(augmented_annotations)\n",
    "\n",
    "# Save augmented annotations\n",
    "save_json(augmented_annotations, augmented_annotations_file)\n",
    "\n",
    "print(f\"Generated {generated_count} augmented images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to dataset with orig_img, orig_target in this\n",
    "dataset = HazmatDataset(\n",
    "    data_dir=augmented_images_dir,\n",
    "    annotations_file=augmented_annotations_file,\n",
    "    transforms=None\n",
    ")\n",
    "visualize_augmentations(dataset, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca7f49",
   "metadata": {},
   "source": [
    "# YOLOv11\n",
    "For Yolov11 we can use the standard ultralytics library for data augmentation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7878367",
   "metadata": {},
   "source": [
    "# example of training a YOLOv11 model with the augmentations applied\n",
    "results = model.train(\n",
    "    data=path+'\\\\yolo\\\\dataset.yaml', \n",
    "    epochs=10,\n",
    "    scale=0.5,\n",
    "    shear=1.1,\n",
    "    device=device,\n",
    "    degrees=10.5,\n",
    "    perspective=0.5,\n",
    "    mosaic=0.5,\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    multiscale=True,\n",
    "    )\n",
    "model.save(\"data\\\\yolo\\\\yolo11n_trained.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d638af4",
   "metadata": {},
   "source": [
    "# Weather Augmentations\n",
    "This code is used to augment images with weather conditions, however the annotation algorithm has not been written yet, therefore this can only be used for human evaluation (e.g. visualising how the model performs under weather augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from typing import Union\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_presets = {\n",
    "    'rain': A.RandomRain(\n",
    "        brightness_coefficient=0.9,  # Slightly darker rain\n",
    "        drop_width=3, # Thicker rain drops\n",
    "        blur_value=5, # Stronger blur effect\n",
    "        p=1, # Always apply rain\n",
    "        drop_length=20), # Longer rain streaks\n",
    "    'sun_flare': A.RandomSunFlare(\n",
    "        flare_roi=(0, 0, 1, 0.5), # Flare in the upper half of the image\n",
    "        angle_lower=0.5, # Angle of tronger sun flare\n",
    "        p=1), # Always apply sun flare\n",
    "    'shadow': A.RandomShadow(\n",
    "        num_shadows_lower=10, # More shadows\n",
    "        num_shadows_upper=15, \n",
    "        shadow_dimension=8, # Larger and darker shadows\n",
    "        shadow_roi=(0, 0, 1, 1), # Shadows across the entire image\n",
    "        p=1), # Always apply shadows\n",
    "    'fog': A.RandomFog(p=1), # Always apply fog\n",
    "    \n",
    "    # 'snow': A.RandomSnow(p=1) # Snow is really unrealistic and not recommended\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5979d1b9",
   "metadata": {},
   "source": [
    "Generate the augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82681c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each file in the input directory and apply the augmentation\n",
    "count = 0\n",
    "input_directory = '../data/processed/prorail_coco_format/formatted_data/train/images'\n",
    "for file_name in os.listdir(input_directory):\n",
    "    if file_name.endswith('.jpg') or file_name.endswith('.png') or file_name.endswith('.jpeg') or file_name.endswith('.bmp') or file_name.endswith('.tiff') or file_name.endswith('.webp') or file_name.endswith('.tif'):\n",
    "        count += 1\n",
    "        types = ['rain', 'sun_flare', 'shadow', 'fog']\n",
    "        # first do rain then sun_flare, shadow and fog\n",
    "        for augmentation in types:\n",
    "            input_image_path = os.path.join(input_directory, file_name)\n",
    "            output_dir = f'../data/processed/prorail_coco_format/augmented_data/{augmentation}'\n",
    "            generate_named_augmented_image(\n",
    "                input_image_path=input_image_path,\n",
    "                output_dir=output_dir,\n",
    "                output_filename_base= str(count),\n",
    "                augmentation=augmentation,\n",
    "                seed=42  # Same seed = same augmentations\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce6044",
   "metadata": {},
   "source": [
    "Visualise the augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations_dir = \"../data/processed/prorail_coco_format/augmented_data/\"\n",
    "\n",
    "visualize_weather_augmentations(input_directory, augmentations_dir, num_images=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
